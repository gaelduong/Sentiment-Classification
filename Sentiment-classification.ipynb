{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate vocabulary for yelp and IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output IMDB-vocab.txt and YELP-vocab.txt. Each file should contain the 10,000 words in the vocabulary, their corresonding id, and their frequency. Each line is a word, its numeric id, and its frequency all tab separated. Example:\n",
    "\n",
    "the 1 20456 <br>\n",
    "a   2 18003<br>\n",
    "and 3 16830<br>\n",
    "of  4 15456<br>\n",
    "in  5 15016<br>\n",
    "...\n",
    "<br>\n",
    "where the is the word, 1 is the id of the word, and 20456 is the frequency of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import csv\n",
    "import collections\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "col = [ [ [\"this\",\"good\",\"good\"],[\"this\",\"is\",\"not\",\"good\"] ],  [[\"yo\",\"damn\",\"good\"],[\"this\",\"is\",\"not\",\"good\"]] ]\n",
    "vocab_dict = {'this':0, 'is':1,'good':2,'not':3,'damn':4,'yo':5}\n",
    "\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "for review in col:\n",
    "    v2 = [0]*len(vocab_dict)\n",
    "    for sentence in review:\n",
    "        v1 = [0]*len(vocab_dict)\n",
    "        for word in sentence:\n",
    "            i = vocab_dict.get(word)\n",
    "            v1[i] += 1\n",
    "            v2[i] += 1\n",
    "        sentence_vectors.append(v1)\n",
    "    review_vectors.append(v2)\n",
    "X_sentences = np.array(vectors)\n",
    "X_reviews = np.array(review_vectors)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "Cs = [1,10,30,50,100]\n",
    "solvers = ['sag']\n",
    "params_grid = {'C':Cs,'solver':solvers}\n",
    "\n",
    "logisticRegression_clf = LogisticRegression()\n",
    "\n",
    "        \n",
    "clf = GridSearchCV(logisticRegression_clf,params_grid,cv=10,scoring = 'accuracy')\n",
    "clf.fit(x_reviews, y_reviews)\n",
    "\n",
    "clf.predict(x_sentences)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strim(line):\n",
    "    #remove <br /><br />\n",
    "    line = line.replace(\"<br /><br />\", ' ');\n",
    "    #remove digits\n",
    "    line = line.translate(str.maketrans('', '', digits))\n",
    "    #remove punctuations\n",
    "    line = re.sub('['+string.punctuation+']', '', line)\n",
    "    #lower case\n",
    "    line = line.lower()\n",
    "    return line\n",
    "\n",
    "def get_top_words(textfile, top=10000):    \n",
    "    ''' Returns the most common words in the textfile.'''\n",
    "    words = collections.Counter()\n",
    "    with open(textfile) as textfile:\n",
    "         for line in textfile:\n",
    "            line = strim(line)\n",
    "            #how often each word appears\n",
    "            words.update(line.split())\n",
    "    return dict(words.most_common(top))\n",
    "\n",
    "IMDB_dict = get_top_words(\"IMDB-train.txt\")\n",
    "yelp_dict = get_top_words(\"yelp-train.txt\")\n",
    "\n",
    "\n",
    "def generate_vocab(fileToWrite, vocab_dict):\n",
    "    with open(fileToWrite, 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    i = 1\n",
    "    for key, value in vocab_dict.items():\n",
    "        vocab_dict[key] = (i,value)\n",
    "        writer.writerow([str(key)+'\\t'+ str(i) + '\\t' + str(value)])\n",
    "        i+=1;\n",
    "\n",
    "#generate IMDB-vocab\n",
    "generate_vocab('IMDB-vocab.txt',IMDB_dict)\n",
    "#generate yelp-vocab\n",
    "generate_vocab('yelp-vocab.txt',yelp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert train, test, valid to id-id-...-label format for yelp and IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train/valid/test file, each line is a data point. Each review should be represented as space separates ids for corresponding words in the review3 and the class label in mentioned in the end of the review as tab separated. Example:\n",
    "\n",
    "<b> 100 8 3 1034 0 </b>\n",
    "\n",
    "Here 0 is the class label and rest of the numbers represent a 4 word review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting...\n",
      "done converting\n"
     ]
    }
   ],
   "source": [
    "def getWordId(word, vocab_dict):\n",
    "    if word in vocab_dict:\n",
    "        return str(vocab_dict[word][0])\n",
    "    else: return '0'\n",
    "             \n",
    "#print(getWordId(\"eagle\"))\n",
    "\n",
    "def convert(fileToRead,fileToWrite,vocab_dict):\n",
    "    with open(fileToRead) as openfile:\n",
    "        reader = csv.reader(openfile,delimiter='\\t')\n",
    "        with open(fileToWrite,'w') as file:\n",
    "            writer = csv.writer(file, delimiter='\\t')\n",
    "            i = 0\n",
    "            for line in reader:\n",
    "                lineToList = strim(line[0]).split()\n",
    "                idsList = list(map(lambda word: getWordId(word,vocab_dict), lineToList))\n",
    "                #print (idsList)\n",
    "                idsLine = ' '.join(idsList)\n",
    "                result = [idsLine,line[1]]\n",
    "                writer.writerow(result)\n",
    "    openfile.close()\n",
    "            \n",
    "print ('converting...')\n",
    "convert(\"IMDB-train.txt\",\"IMDB-train.txt\",IMDB_dict)\n",
    "convert(\"IMDB-valid.txt\",\"IMDB-valid.txt\",IMDB_dict)\n",
    "convert(\"IMDB-test.txt\",\"IMDB-test.txt\",IMDB_dict)\n",
    "        \n",
    "convert(\"yelp-train.txt\",\"yelp-train.txt\",yelp_dict)\n",
    "convert(\"yelp-valid.txt\",\"yelp-valid.txt\",yelp_dict)\n",
    "convert(\"yelp-test.txt\",\"yelp-test.txt\",yelp_dict)\n",
    "\n",
    "print('done converting')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make BBOW and FBOW data for train, test and valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BBOW \n",
    "\n",
    "x = <br>\n",
    "0 0 0 1 ... 1 <br>\n",
    "0 1 0 0 ... 0 <br>\n",
    "... <br>\n",
    "0 0 0 1 ... 1 <br>\n",
    "0 1 0 0 ... 0 <br>\n",
    "\n",
    "y = <br>\n",
    "0 <br>\n",
    "1 <br>\n",
    ".. <br>\n",
    "0 <br>\n",
    "1 <br>\n",
    "\n",
    "### FBOW\n",
    "\n",
    "x = <br>\n",
    "12 3 0 9 ... 1 <br>\n",
    "30 1 28 10 ... 0 <br>\n",
    "... <br>\n",
    "10 20 30 1 ... 1 <br>\n",
    "22 1 17 25 ... 0 <br>\n",
    "\n",
    "y = <br>\n",
    "0 <br>\n",
    "1 <br>\n",
    ".. <br>\n",
    "0 <br>\n",
    "1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bbow_data(file) return x=[[0,0,1...],[0,0,..] ] , y= [[0],[1],....]\n",
    "def bbow_data(file):\n",
    "    size = 0\n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f,delimiter='\\t')\n",
    "        size = len(list(reader))\n",
    "    x = np.zeros((size,10000))\n",
    "    y = np.zeros((size,1))\n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f,delimiter='\\t')\n",
    "        line_i = 0\n",
    "        for line in reader:\n",
    "            #print (bbow_v(line[0]))\n",
    "            \n",
    "            lineToList = line[0].split()\n",
    "            for id in lineToList:\n",
    "                id = int(id)\n",
    "                if(id !=0):\n",
    "                    x[line_i][id-1] = 1\n",
    "            \n",
    "            \n",
    "            y[line_i][0] = line[1]\n",
    "            line_i += 1\n",
    "    \n",
    "    return x,y\n",
    "#print ('running')\n",
    "#x,y = bbow(\"IMDB-train-2.txt\")\n",
    "#print (x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fbow return x=[[20,10,1...],[21,99,..]] , y= [[0],[1],....]\n",
    "def fbow_data(file):\n",
    "    size = 0\n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f,delimiter='\\t')\n",
    "        size = len(list(reader))\n",
    "    x = np.zeros((size,10000))\n",
    "    y = np.zeros((size,1))\n",
    "    \n",
    "    with open(file) as f:\n",
    "        reader = csv.reader(f,delimiter='\\t')\n",
    "        line_i = 0\n",
    "        for line in reader:\n",
    "            lineToList = line[0].split()\n",
    "            for id in lineToList:\n",
    "                id = int(id)\n",
    "                if(id !=0):\n",
    "                    x[line_i][id-1] = lineToList.count(str(id))\n",
    "                    \n",
    "            y[line_i][0] = line[1]\n",
    "            \n",
    "            line_i += 1\n",
    "    \n",
    "    return x,y\n",
    "#print ('running')\n",
    "#x,y = fbow(\"yelp-train-2.txt\")\n",
    "#print (x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load BBOW and FBOW data for IMDB and YELP ONLY ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_bbow_train = bbow_data(\"yelp-train.txt\")\n",
    "yelp_bbow_test = bbow_data(\"yelp-test.txt\")\n",
    "yelp_bbow_valid = bbow_data(\"yelp-valid.txt\")\n",
    "\n",
    "yelp_fbow_train = fbow_data(\"yelp-train.txt\")\n",
    "yelp_fbow_test = fbow_data(\"yelp-test.txt\")\n",
    "yelp_fbow_valid = fbow_data(\"yelp-valid.txt\")\n",
    "\n",
    "IMDB_bbow_train = bbow_data(\"IMDB-train.txt\")\n",
    "IMDB_bbow_test = bbow_data(\"IMDB-test.txt\")\n",
    "IMDB_bbow_valid = bbow_data(\"IMDB-valid.txt\")\n",
    "\n",
    "IMDB_fbow_train = fbow_data(\"IMDB-train.txt\")\n",
    "IMDB_fbow_test = fbow_data(\"IMDB-test.txt\")\n",
    "IMDB_fbow_valid = fbow_data(\"IMDB-valid.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(Enum):\n",
    "    Random = 1\n",
    "    Majority = 2\n",
    "    BernouilliNB = 3\n",
    "    GaussianNB = 4\n",
    "    LinearSVM = 5\n",
    "    DecisionTree = 6\n",
    "\n",
    "#takes 3 datasets train,test,valid (IMDB or yelp)\n",
    "def a3(train,test,valid,classifier):\n",
    "    #read 3 train.txt, test.txt, valid.txt\n",
    "    x_train,y_train = train\n",
    "    x_test,y_test = test\n",
    "    x_valid,y_valid = valid\n",
    "    \n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    y_valid = y_valid.ravel()\n",
    "    \n",
    "    \n",
    "    xc,yc = check_X_y(x_train,y_train)\n",
    "    \n",
    "    x_train_valid = np.concatenate((x_train, x_valid))\n",
    "    y_train_valid = np.concatenate((y_train, y_valid))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    # majority classifier\n",
    "    if(classifier == Classifier.Majority):\n",
    "        major_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "        major_clf.fit(xc,yc)\n",
    "\n",
    "        y_major_pred = major_clf.predict(x_test)\n",
    "        print(\"Major classifier\")\n",
    "        #print (y_major_pred)\n",
    "        print(\"Accuracy score: \", accuracy_score(y_test,y_major_pred))\n",
    "        print(\"F1 score: \", f1_score(y_test,y_major_pred,average=\"macro\"))\n",
    "        #print(classification_report(y_test,y_major_pred))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # rand classifier\n",
    "    if(classifier == Classifier.Random):\n",
    "        rand_clf = DummyClassifier(strategy=\"uniform\")\n",
    "        rand_clf.fit(xc,yc)\n",
    "\n",
    "        y_rand_pred = rand_clf.predict(x_test)\n",
    "        print(\"Random classifier\")\n",
    "        #print (y_rand_pred)\n",
    "        print(\"Accuracy score: \", accuracy_score(y_test,y_rand_pred))\n",
    "        print(\"F1 score: \", f1_score(y_test,y_rand_pred,average=\"macro\"))\n",
    "        #print(classification_report(y_test,y_rand_pred))\n",
    "        return\n",
    "\n",
    "    \n",
    "    if(classifier == Classifier.BernouilliNB):\n",
    "        #NAIVE BAYES\n",
    "        # bernouille NB\n",
    "        \n",
    "        \n",
    "        alpha_range = [0,0.01,0.1,0.5,1,2,3,4]\n",
    "        \n",
    "        best_alpha_f1 = (alpha_range[0],0)\n",
    "        alpha_f1_record = []\n",
    "        for a in alpha_range:\n",
    "            berNB_clf = BernoulliNB(alpha=a, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "            berNB_clf.fit(x_train, y_train)\n",
    "            #BernoulliNB(alpha=a, binarize=0.1, class_prior=None, fit_prior=True)\n",
    "            y_berNB_pred = berNB_clf.predict(x_valid)\n",
    "            F1 = f1_score(y_valid,y_berNB_pred,average='macro')\n",
    "            alpha_f1_record.append( (a,F1))\n",
    "            if(F1 > best_alpha_f1[1]):\n",
    "                best_alpha_f1 = (a,F1)\n",
    "        \n",
    "        \n",
    "        #\n",
    "        \n",
    "        #\n",
    "        best_alpha = best_alpha_f1[0]\n",
    "        print (\"best alpha \",best_alpha)\n",
    "        berNB_clf = BernoulliNB(alpha=best_alpha, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "        berNB_clf.fit(x_train, y_train)\n",
    "        \n",
    "        print(\"Bernouilli NB classifier\")\n",
    "        \n",
    "        print(\"alpha range: \", alpha_range)\n",
    "        print (alpha_f1_record)\n",
    "        #print(y_berNB_pred)\n",
    "        print(\"Accuracy score on test set: \", accuracy_score(y_test,berNB_clf.predict(x_test)))\n",
    "        print(\"F1 score train: \", f1_score(y_train,berNB_clf.predict(x_train),average='macro'))\n",
    "        print(\"F1 score valid: \", f1_score(y_valid,berNB_clf.predict(x_valid),average='macro'))\n",
    "        print(\"F1 score test: \", f1_score(y_test,berNB_clf.predict(x_test),average='macro'))\n",
    "        #print(classification_report(y_test,y_berNB_pred))\n",
    "        return\n",
    "\n",
    "    # gaussian NB\n",
    "    if(classifier == Classifier.GaussianNB):\n",
    "        gauNB_clf = GaussianNB()\n",
    "        gauNB_clf.fit(x_train, y_train)\n",
    "\n",
    "        y_gauNB_pred = gauNB_clf.predict(x_test)\n",
    "        print(\"Gaussian NB classifier\")\n",
    "        #print(y_gauNB_pred)\n",
    "        print (\"No hyperparameters to be learned\")\n",
    "        print(\"Accuracy score on test set: \", accuracy_score(y_test,y_gauNB_pred))\n",
    "        print(\"F1 score train: \", f1_score(y_train,gauNB_clf.predict(x_train),average='macro'))\n",
    "        print(\"F1 score valid: \", f1_score(y_valid,gauNB_clf.predict(x_valid),average='macro'))\n",
    "        print(\"F1 score test: \", f1_score(y_test,y_gauNB_pred,average='macro'))\n",
    "        #print(classification_report(y_test,y_gauNB_pred))\n",
    "        return\n",
    "\n",
    "    \n",
    "    # SVM\n",
    "    if(classifier == Classifier.LinearSVM):\n",
    "        \n",
    "        ps = PredefinedSplit([0]*len(x_train) + [1]*len(x_valid))\n",
    "       \n",
    "        \n",
    "        linearSVM_clf = LinearSVC()\n",
    "        \n",
    "        Cs = [1,10,100]\n",
    "        tols = [1e-5,1e-4,1e-3,1e-2]\n",
    "        max_iters = [1,10,100]\n",
    "        \n",
    "        print(\"C range \", Cs)\n",
    "        print(\"tol range \", tols)\n",
    "        print(\"max_iter range \", max_iters)\n",
    "        params_grid = {'C':Cs,'tol':tols,'max_iter':max_iters}\n",
    "        \n",
    "        clf = RandomizedSearchCV(linearSVM_clf,params_grid,cv=2,scoring = 'f1_macro')\n",
    "    \n",
    "        clf.fit(x_train_valid, y_train_valid)\n",
    "        print(clf.best_params_)\n",
    "        print(\"Accuracy score on test set: \", accuracy_score(y_test,clf.predict(x_test)))\n",
    "        print(\"F1 score train: \", f1_score(y_train,clf.predict(x_train),average='macro'))\n",
    "        print(\"F1 score valid: \", f1_score(y_valid,clf.predict(x_valid),average='macro'))\n",
    "        print(\"F1 score test: \", f1_score(y_test,clf.predict(x_test),average='macro'))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # DT\n",
    "    if(classifier == Classifier.DecisionTree):\n",
    "        DT_clf = DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "        params_grid = {'max_depth':[10,20,None],'min_samples_leaf':[1,5,10,15],'criterion':['gini']}\n",
    "        print ('range ',params_grid)\n",
    "        \n",
    "        clf = RandomizedSearchCV(DT_clf,params_grid,cv=2,verbose=1)\n",
    "        clf.fit(x_train_valid,y_train_valid)\n",
    "        print(clf.best_params_)\n",
    "        #print(\"Accuracy score on test set: \", accuracy_score(y_test,clf.predict(x_test)))\n",
    "        print(\"F1 score train: \", f1_score(y_train,clf.predict(x_train),average='macro'))\n",
    "        print(\"F1 score valid: \", f1_score(y_valid,clf.predict(x_valid),average='macro'))\n",
    "        print(\"F1 score test: \", f1_score(y_test,clf.predict(x_test),average='macro'))\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----YELP BBOW-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Classifier & Majority Classifier (YELP BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random classifier\n",
      "Accuracy score:  0.206\n",
      "F1 score:  0.19171164871579427\n",
      "Major classifier\n",
      "Accuracy score:  0.351\n",
      "F1 score:  0.10392301998519615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duonggael/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Question a\n",
    "a3(yelp_bbow_train, yelp_bbow_test, yelp_bbow_valid, Classifier.Random)\n",
    "a3(yelp_bbow_train, yelp_bbow_test, yelp_bbow_valid, Classifier.Majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernouilli Naive Bayes Classifier (YELP BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duonggael/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "Bernouilli NB classifier\n",
      "alpha range:  [0, 0.01, 0.1, 0.5, 1, 2, 3, 4]\n",
      "[(0, 0.28119867051278813), (0.01, 0.3834688068328239), (0.1, 0.36928058341966186), (0.5, 0.3484823877249245), (1, 0.32787582466183035), (2, 0.3017452114165385), (3, 0.264402649039394), (4, 0.2442534522248531)]\n",
      "Accuracy score on test set:  0.4375\n",
      "F1 score train:  0.7701132102709616\n",
      "F1 score valid:  0.3834688068328239\n",
      "F1 score test:  0.3610618444272477\n"
     ]
    }
   ],
   "source": [
    "a3(yelp_bbow_train, yelp_bbow_test, yelp_bbow_valid, Classifier.BernouilliNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier (YELP BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C range  [1, 10, 100]\n",
      "tol range  [1e-05, 0.0001, 0.001, 0.01]\n",
      "max_iter range  [1, 10, 100]\n",
      "{'tol': 1e-05, 'max_iter': 10, 'C': 10}\n",
      "Accuracy score on test set:  0.466\n",
      "F1 score train:  0.8968780457501515\n",
      "F1 score valid:  0.8939968795056135\n",
      "F1 score test:  0.4232184434136304\n"
     ]
    }
   ],
   "source": [
    "a3(yelp_bbow_train, yelp_bbow_test, yelp_bbow_valid, Classifier.LinearSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier (YELP BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running...')\n",
    "a3(yelp_bbow_train, yelp_bbow_test, yelp_bbow_valid, Classifier.DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- YELP FBOW-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier (YELP FBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB classifier\n",
      "No hyperparameters to be learned\n",
      "Accuracy score on test set:  0.275\n",
      "F1 score train:  0.6554568775139135\n",
      "F1 score valid:  0.2377725803613623\n",
      "F1 score test:  0.2313890394496927\n"
     ]
    }
   ],
   "source": [
    "a3(yelp_fbow_train, yelp_fbow_test, yelp_fbow_valid, Classifier.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier (YELP FBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C range  [1, 10, 100]\n",
      "tol range  [1e-05, 0.0001, 0.001, 0.01]\n",
      "max_iter range  [1, 10, 100]\n",
      "{'tol': 1e-05, 'max_iter': 10, 'C': 1}\n",
      "Accuracy score on test set:  0.4885\n",
      "F1 score train:  0.8089433356523472\n",
      "F1 score valid:  0.8011106117374922\n",
      "F1 score test:  0.44080885452995844\n"
     ]
    }
   ],
   "source": [
    "a3(yelp_fbow_train, yelp_fbow_test, yelp_fbow_valid, Classifier.LinearSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier (YELP FBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 1, 'max_depth': 10, 'criterion': 'gini'}\n",
      "F1 score train:  0.4677385842989718\n",
      "F1 score valid:  0.44628993660866617\n",
      "F1 score test:  0.2785697732802583\n"
     ]
    }
   ],
   "source": [
    "a3(yelp_fbow_train, yelp_fbow_test, yelp_fbow_valid, Classifier.DecisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- IMDB BBOW-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random & Majority Classifier (IMDB BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random classifier\n",
      "Accuracy score:  0.4966\n",
      "F1 score:  0.49659145494199275\n",
      "Major classifier\n",
      "Accuracy score:  0.5\n",
      "F1 score:  0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duonggael/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "a3(IMDB_bbow_train, IMDB_bbow_test, IMDB_bbow_valid,Classifier.Random)\n",
    "a3(IMDB_bbow_train, IMDB_bbow_test, IMDB_bbow_valid,Classifier.Majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernouilli Naive Bayes Classifier (IMDB BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duonggael/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Bernouilli NB classifier\n",
      "alpha range:  [0, 0.01, 0.1, 0.5, 1, 2, 3, 4]\n",
      "[(0, 0.8416702830954341), (0.01, 0.8434652477196463), (0.1, 0.8440634968239715), (0.5, 0.8428540489524542), (1, 0.8421430136279198), (2, 0.8417288666218146), (3, 0.8409158444817308), (4, 0.8410958605831917)]\n",
      "Accuracy score on test set:  0.83248\n",
      "F1 score train:  0.8717611744131653\n",
      "F1 score valid:  0.8440634968239715\n",
      "F1 score test:  0.8323167704370142\n"
     ]
    }
   ],
   "source": [
    "a3(IMDB_bbow_train, IMDB_bbow_test, IMDB_bbow_valid, Classifier.BernouilliNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier (IMDB BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C range  [1, 10, 100]\n",
      "tol range  [1e-05, 0.0001, 0.001, 0.01]\n",
      "max_iter range  [1, 10, 100]\n",
      "{'tol': 0.0001, 'max_iter': 10, 'C': 1}\n",
      "Accuracy score on test set:  0.84324\n",
      "F1 score train:  0.9592489229232437\n",
      "F1 score valid:  0.9584786044400819\n",
      "F1 score test:  0.8430564325257395\n"
     ]
    }
   ],
   "source": [
    "a3(IMDB_bbow_train, IMDB_bbow_test, IMDB_bbow_valid,Classifier.LinearSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier (IMDB BBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "a3(IMDB_bbow_train, IMDB_bbow_test, IMDB_bbow_valid,Classifier.DecisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----IMDB FBOW-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier (IMDB FBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB classifier\n",
      "No hyperparameters to be learned\n",
      "Accuracy score on test set:  0.64556\n",
      "F1 score train:  0.7743603382010854\n",
      "F1 score valid:  0.7048652925838272\n",
      "F1 score test:  0.6295127390846781\n"
     ]
    }
   ],
   "source": [
    "a3(IMDB_fbow_train, IMDB_fbow_test, IMDB_fbow_valid,Classifier.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier (IMDB FBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C range  [1, 10, 100]\n",
      "tol range  [1e-05, 0.0001, 0.001, 0.01]\n",
      "max_iter range  [1, 10, 100]\n",
      "{'tol': 0.0001, 'max_iter': 10, 'C': 10}\n",
      "Accuracy score on test set:  0.85024\n",
      "F1 score train:  0.9265944012734234\n",
      "F1 score valid:  0.9266881755358323\n",
      "F1 score test:  0.8502187181168699\n"
     ]
    }
   ],
   "source": [
    "a3(IMDB_fbow_train, IMDB_fbow_test, IMDB_fbow_valid,Classifier.LinearSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier (IMDB FBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3(IMDB_fbow_train, IMDB_fbow_test, IMDB_fbow_valid,Classifier.DecisionTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
